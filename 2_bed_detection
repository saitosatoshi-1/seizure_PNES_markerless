"""
Bed Region Best-Frame Detection using YOLO (Ultralytics)
--------------------------------------------------------
- Detect bed region in video using segmentation (preferred) and detection (fallback).
- Save best-confidence bed frame as PNG.
- Save JSON/CSV metadata.
- Save visualization video.

Model files required:
    models/yolo11s.pt
    models/yolo11s-seg.pt
"""

import os
import json
import csv
import argparse
from pathlib import Path
import cv2
import numpy as np
from ultralytics import YOLO


# ------------------------------------------------------------
# Utility: Get class ID from YOLO model by name (e.g., "bed")
# ------------------------------------------------------------
def get_cls_id_by_name(model, name="bed"):
    for i, n in model.names.items():
        if n == name:
            return i
    return None


# ------------------------------------------------------------
# Segmentation-based update
# ------------------------------------------------------------
def update_best_from_seg(res, frame_idx, vis_w, vis_h):
    if res.masks is None or len(res.masks.data) == 0:
        return False, None, None

    confs = res.boxes.conf.cpu().numpy()
    xyxy  = res.boxes.xyxy.cpu().numpy()
    masks = res.masks.data.cpu().numpy()

    k = int(np.argmax(confs))
    conf = float(confs[k])

    x1, y1, x2, y2 = map(float, xyxy[k])
    w = x2 - x1
    h = y2 - y1

    # mask → uint8
    m = masks[k]
    mask_uint8 = (m > 0.5).astype(np.uint8)
    area_mask_px = int(mask_uint8.sum())
    area_mask_ratio = area_mask_px / float(vis_w * vis_h)

    # rotated min-area rectangle
    cnts, _ = cv2.findContours(mask_uint8, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
    area_rot_rect_px = None
    if cnts:
        c = max(cnts, key=cv2.contourArea)
        (_, _), (rw, rh), _ang = cv2.minAreaRect(c)
        area_rot_rect_px = float(rw * rh)

    area_bbox_px = float(max(0.0, w) * max(0.0, h))

    upd = {
        "frame": frame_idx,
        "conf": conf,
        "x1": x1,
        "y1": y1,
        "x2": x2,
        "y2": y2,
        "cx": x1 + w/2.0,
        "cy": y1 + h/2.0,
        "w": w,
        "h": h,
        "area_mask_px": area_mask_px,
        "area_mask_ratio": area_mask_ratio,
        "area_rot_rect_px": area_rot_rect_px,
        "area_bbox_px": area_bbox_px,
    }
    return True, mask_uint8, upd


# ------------------------------------------------------------
# Detection-based fallback update
# ------------------------------------------------------------
def update_best_from_det(res, frame_idx):
    if res.boxes is None or len(res.boxes) == 0:
        return False, None

    confs = res.boxes.conf.cpu().numpy()
    xyxy  = res.boxes.xyxy.cpu().numpy()

    k = int(np.argmax(confs))
    conf = float(confs[k])

    x1, y1, x2, y2 = map(float, xyxy[k])
    w = x2 - x1
    h = y2 - y1

    area_bbox_px = float(max(0.0, w) * max(0.0, h))

    upd = {
        "frame": frame_idx,
        "conf": conf,
        "x1": x1,
        "y1": y1,
        "x2": x2,
        "y2": y2,
        "cx": x1 + w/2.0,
        "cy": y1 + h/2.0,
        "w": w,
        "h": h,
        "area_mask_px": None,
        "area_mask_ratio": None,
        "area_rot_rect_px": None,
        "area_bbox_px": area_bbox_px,
    }
    return True, upd



# ------------------------------------------------------------
# Main workflow:
# 1. Visualize the human silhouette (person class)
# 2. Try bed segmentation → then bed detection, updating results
# 3. Update best_bed (the detection with the highest confidence)
# 4. Save a PNG snapshot whenever best_bed is updated
# 5. Save progress snapshots (heartbeat PNG) as well
# 6. Write out the visualization frames
# → YOLO runs on every frame,
# → automatically extracting the “best shot” of the bed region.
# ------------------------------------------------------------

def main():
    parser = argparse.ArgumentParser(description="Bed Best-Frame Detector")
    parser.add_argument("--video", required=True, help="Input video path")
    parser.add_argument("--outdir", default="outputs", help="Output directory")
    args = parser.parse_args()

    video_path = args.video
    outdir = Path(args.outdir)
    outdir.mkdir(parents=True, exist_ok=True)

    # model load
    seg_model = YOLO("models/yolo11s-seg.pt")
    seg_bed_model = YOLO("models/yolo11s-seg.pt")
    det_model = YOLO("models/yolo11s.pt")

    bed_cls_id_seg = get_cls_id_by_name(seg_bed_model, "bed")
    bed_cls_id_det = get_cls_id_by_name(det_model, "bed")
    if bed_cls_id_seg is None and bed_cls_id_det is None:
        raise RuntimeError("Model does not contain class 'bed'.")

    # video IO
    cap = cv2.VideoCapture(video_path)
    if not cap.isOpened():
        raise RuntimeError(f"Cannot open video: {video_path}")

    orig_fps = cap.get(cv2.CAP_PROP_FPS) or 30.0
    in_w  = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))
    in_h  = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))
    frame_size = (in_w, in_h)

    out_try_path = str(outdir / "output_raw.mp4")
    out_qt_path  = str(outdir / "output_qt.mp4")
    best_json    = str(outdir / "best_bed.json")
    best_csv     = str(outdir / "best_bed.csv")
    final_png    = str(outdir / "best_bed.png")
    png_dir      = outdir / "best_frames"
    png_dir.mkdir(exist_ok=True)

    fourcc = cv2.VideoWriter_fourcc(*"mp4v")
    out = cv2.VideoWriter(out_try_path, fourcc, orig_fps, frame_size)
    if not out.isOpened():
        raise RuntimeError("VideoWriter cannot open.")

    best_bed = {
        "frame": None,
        "conf": -1.0,
        "x1": None,
        "y1": None,
        "x2": None,
        "y2": None,
        "cx": None,
        "cy": None,
        "w": None,
        "h": None,
        "area_mask_px": None,
        "area_mask_ratio": None,
        "area_rot_rect_px": None,
        "area_bbox_px": None,
    }

    frame_idx = 0
    best_png_img = None
    saved_updates = 0
    heartbeat_every = 90

    # --------------------------------------------------
    # Loop
    # --------------------------------------------------
    while True:
        ret, frame = cap.read()
        if not ret:
            break

        seg_people = seg_model(frame)
        vis = seg_people[0].plot()
        vis_h, vis_w = vis.shape[:2]

        if (vis_w, vis_h) != frame_size:
            vis = cv2.resize(vis, frame_size)
            vis_h, vis_w = frame_size[1], frame_size[0]

        updated = False

        # segmentation preferred
        if bed_cls_id_seg is not None:
            res_seg = seg_bed_model.predict(frame, classes=[bed_cls_id_seg], verbose=False)[0]
            ok, mask_uint8, upd = update_best_from_seg(res_seg, frame_idx, vis_w, vis_h)
            if ok and upd["conf"] > best_bed["conf"]:
                best_bed.update(upd)
                updated = True

                overlay = vis.copy()
                overlay[mask_uint8.astype(bool)] = (
                    0.6 * overlay[mask_uint8.astype(bool)] + 0.4 * np.array((0, 255, 0))
                ).astype(np.uint8)
                vis = cv2.addWeighted(overlay, 1.0, vis, 0.0, 0)

        # detection fallback
        if not updated and bed_cls_id_det is not None:
            res_det = det_model.predict(frame, classes=[bed_cls_id_det], verbose=False)[0]
            ok, upd = update_best_from_det(res_det, frame_idx)
            if ok and upd["conf"] > best_bed["conf"]:
                best_bed.update(upd)
                updated = True

        # draw best
        if best_bed["conf"] > 0:
            bx1, by1 = int(best_bed["x1"]), int(best_bed["y1"])
            bx2, by2 = int(best_bed["x2"]), int(best_bed["y2"])
            cv2.rectangle(vis, (bx1, by1), (bx2, by2), (0, 255, 0), 2)
            cv2.putText(
                vis,
                f"best bed conf={best_bed['conf']:.2f}",
                (bx1, max(0, by1 - 10)),
                cv2.FONT_HERSHEY_SIMPLEX,
                0.6,
                (0, 255, 0),
                2,
            )

        # save update
        if updated:
            png_path = png_dir / f"bed_best_frame{frame_idx:06d}.png"
            ok = cv2.imwrite(str(png_path), vis)
            if ok:
                best_png_img = vis.copy()
            saved_updates += 1
            print(f"[Update] frame={best_bed['frame']} conf={best_bed['conf']:.4f}")

        # heartbeat
        if frame_idx % heartbeat_every == 0:
            hb_path = png_dir / f"heartbeat_{frame_idx:06d}.png"
            cv2.imwrite(str(hb_path), vis)

        out.write(vis)
        frame_idx += 1

    cap.release()
    out.release()

    # ffmpeg convert
    os.system(
        f"ffmpeg -y -i {out_try_path} -vcodec libx264 -pix_fmt yuv420p "
        f"-profile:v baseline -level 3.0 -movflags +faststart {out_qt_path}"
    )

    # save best PNG
    if best_png_img is not None:
        cv2.imwrite(final_png, best_png_img)

    # save JSON
    with open(best_json, "w") as f:
        json.dump(best_bed, f, indent=2)

    # save CSV
    with open(best_csv, "w", newline="") as f:
        writer = csv.DictWriter(
            f,
            fieldnames=[
                "frame",
                "conf",
                "x1",
                "y1",
                "x2",
                "y2",
                "cx",
                "cy",
                "w",
                "h",
                "area_mask_px",
                "area_mask_ratio",
                "area_rot_rect_px",
                "area_bbox_px",
            ],
        )
        writer.writeheader()
        writer.writerow(best_bed)


if __name__ == "__main__":
    main()
